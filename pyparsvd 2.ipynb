{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9db85705",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import types\n",
    "\n",
    "# --- MPI Dummy Patch for PyParSVD ---\n",
    "mpi_mod = types.ModuleType(\"mpi4py.MPI\")\n",
    "class CommDummy:\n",
    "    def Get_rank(self): return 0\n",
    "    def Get_size(self): return 1\n",
    "mpi_mod.COMM_WORLD = CommDummy()\n",
    "sys.modules['mpi4py.MPI'] = mpi_mod\n",
    "\n",
    "# Add local PyParSVD repo to path\n",
    "# Adjust the relative path 'PyParSVD' if your folder has a different name or location\n",
    "sys.path.insert(0, os.path.join(os.getcwd(), 'PyParSVD'))\n",
    "\n",
    "import json\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "from pyparsvd.parsvd_serial import ParSVD_Serial\n",
    "from pyparsvd.parsvd_parallel import ParSVD_Parallel\n",
    "from memory_profiler import memory_usage  # local import from cloned repo\n",
    "from memory_profiler import memory_usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61b78b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import types\n",
    "\n",
    "# --- MPI Dummy Patch for PyParSVD ---\n",
    "mpi_mod = types.ModuleType(\"mpi4py.MPI\")\n",
    "class CommDummy:\n",
    "    def Get_rank(self): return 0\n",
    "    def Get_size(self): return 1\n",
    "mpi_mod.COMM_WORLD = CommDummy()\n",
    "sys.modules['mpi4py.MPI'] = mpi_mod\n",
    "\n",
    "# Add local PyParSVD repo to path (adjust 'PyParSVD' if needed)\n",
    "sys.path.insert(0, os.path.join(os.getcwd(), 'PyParSVD'))\n",
    "\n",
    "import json\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "from pyparsvd.parsvd_serial import ParSVD_Serial\n",
    "from pyparsvd.parsvd_parallel import ParSVD_Parallel\n",
    "from memory_profiler import memory_usage\n",
    "\n",
    "# %%\n",
    "\n",
    "def run_pyparsvd(nc_path: str,\n",
    "                 var_name: str = 'msl',\n",
    "                 k: int = 200,\n",
    "                 ff: float = 0.95,\n",
    "                 batch_size: int = 100,\n",
    "                 algorithm: str = 'serial',\n",
    "                 output_file: str = None,\n",
    "                 **mem_kwargs) -> dict:\n",
    "    \"\"\"\n",
    "    Unified PyParSVD driver using local repo.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    nc_path     : Path to NetCDF ('slp.nc' or 't2m.nc').\n",
    "    var_name    : Variable name ('msl' or 't2m').\n",
    "    k           : Number of singular modes.\n",
    "    ff          : Forget factor for streaming.\n",
    "    batch_size  : Number of columns per streaming batch.\n",
    "    algorithm   : 'serial' or 'parallel'.\n",
    "    output_file : Optional JSONL path to append results.\n",
    "    **mem_kwargs: Extra args for memory_usage.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict with keys:\n",
    "      'method', 'dataset', 'shape', 'k', 'batch_size', 'elapsed_time_s',\n",
    "      'peak_memory_MiB', 'reconstruction_error', 'energy_captured',\n",
    "      'cond_full', 'cond_trunc'\n",
    "    \"\"\"\n",
    "    # Load & reshape data: (grid_points, time)\n",
    "    ds = xr.open_dataset(nc_path)\n",
    "    data = ds[var_name].values  # (time, lat, lon)\n",
    "    nt, ny, nx = data.shape\n",
    "    A = data.reshape(nt, ny*nx).T  # (m, n)\n",
    "    m, n = A.shape\n",
    "\n",
    "    # Bound k and batch_size\n",
    "    k = min(k, m, n)\n",
    "    batch_size = min(batch_size, n)\n",
    "\n",
    "    # Initialize model\n",
    "    if algorithm.lower() == 'serial':\n",
    "        model = ParSVD_Serial(K=k, ff=ff)\n",
    "    else:\n",
    "        model = ParSVD_Parallel(K=k, ff=ff)\n",
    "\n",
    "    # Define compute task\n",
    "    def compute_task():\n",
    "        # Initialize with first batch\n",
    "        model.initialize(A[:, :batch_size])\n",
    "        # Stream remaining batches\n",
    "        for start in range(batch_size, n, batch_size):\n",
    "            end = min(start + batch_size, n)\n",
    "            model.incorporate_data(A[:, start:end])\n",
    "        # Retrieve modes and singular values\n",
    "        modes = model._modes               # (m, k)\n",
    "        sing_vals = model._singular_values  # (k,)\n",
    "        # Approximate final Vᵀ from projection: Vᵀ ≈ diag(1/σ) · Uᵀ · A\n",
    "        Vt = (modes.T @ A) / sing_vals[:, None]\n",
    "        return modes, sing_vals, Vt\n",
    "\n",
    "    # Profile runtime & memory once\n",
    "    t0 = time.time()\n",
    "    peak_mem, (modes, sing_vals, Vt) = memory_usage(\n",
    "        (compute_task, (), {}),\n",
    "        retval=True,\n",
    "        max_usage=True,\n",
    "        **mem_kwargs\n",
    "    )\n",
    "    elapsed = time.time() - t0\n",
    "\n",
    "    # Reconstruction error\n",
    "    A_rec = modes @ np.diag(sing_vals) @ Vt\n",
    "    recon_err = np.linalg.norm(A - A_rec, ord='fro')\n",
    "\n",
    "    # Energy captured\n",
    "    total_energy = np.linalg.norm(A, ord='fro')**2\n",
    "    energy = float(np.sum(sing_vals**2) / total_energy)\n",
    "\n",
    "    # Condition numbers\n",
    "    cond_full = None\n",
    "    cond_trunc = float(sing_vals[0] / sing_vals[-1]) if k > 1 else np.nan\n",
    "\n",
    "    # Package results\n",
    "    results = {\n",
    "        'method': f'PyParSVD ({algorithm})',\n",
    "        'dataset': os.path.basename(nc_path),\n",
    "        'shape': (m, n),\n",
    "        'k': k,\n",
    "        'batch_size': batch_size,\n",
    "        'elapsed_time_s': float(elapsed),\n",
    "        'peak_memory_MiB': float(peak_mem),\n",
    "        'reconstruction_error': float(recon_err),\n",
    "        'energy_captured': float(energy),\n",
    "        'cond_full': cond_full,\n",
    "        'cond_trunc': cond_trunc\n",
    "    }\n",
    "\n",
    "    # Print unified report\n",
    "    print(f\"=== {results['method']} on {results['dataset']}\"\n",
    "          f\" (m={m}, n={n}, k={k}, batch_size={batch_size}) ===\")\n",
    "    for key, val in results.items():\n",
    "        if key not in ('method', 'dataset', 'shape'):\n",
    "            print(f\"{key.replace('_',' ').capitalize():<22}: {val}\")\n",
    "\n",
    "    # Append to JSONL\n",
    "    if output_file:\n",
    "        os.makedirs(os.path.dirname(output_file) or '.', exist_ok=True)\n",
    "        safe = {kk: (vv.item() if hasattr(vv, 'item') else vv)\n",
    "                for kk, vv in results.items()}\n",
    "        with open(output_file, 'a') as f:\n",
    "            f.write(json.dumps(safe) + '\\n')\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99bced2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== PyParSVD (serial) on slp.nc (m=16261, n=16071, k=10, batch_size=100) ===\n",
      "K                     : 10\n",
      "Batch size            : 100\n",
      "Elapsed time s        : 13.557955980300903\n",
      "Peak memory mib       : 1253.87890625\n",
      "Reconstruction error  : 2098938.5\n",
      "Energy captured       : 0.0675780177116394\n",
      "Cond full             : None\n",
      "Cond trunc            : 2414.977783203125\n"
     ]
    }
   ],
   "source": [
    "res_serial = run_pyparsvd(\n",
    "     'slp.nc', var_name='msl', k=10, ff=0.95,\n",
    "     batch_size=100, algorithm='serial',\n",
    "     output_file='svd_results/pyparsvd_k10_ff95.jsonl',\n",
    "     multiprocess=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
