{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c0699e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "from scipy.linalg import qr, svd\n",
    "from memory_profiler import memory_usage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95d311e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_streaming_svd(nc_path: str,\n",
    "                      var_name: str = 'msl',\n",
    "                      k: int = None,\n",
    "                      ff: float = 1.0,\n",
    "                      batch_size: int = 100,\n",
    "                      output_file: str = None,\n",
    "                      **mem_kwargs) -> dict:\n",
    "    \"\"\"\n",
    "    Unified Streaming SVD driver with singleâ€‘pass profiling and correct reconstruction.\n",
    "    \"\"\"\n",
    "    # Load & reshape data\n",
    "    ds = xr.open_dataset(nc_path)\n",
    "    data = ds[var_name].values        # (time, lat, lon)\n",
    "    nt, ny, nx = data.shape\n",
    "    A = data.reshape(nt, ny*nx).T     # (m, n)\n",
    "    m, n = A.shape\n",
    "\n",
    "    # Determine k\n",
    "    if k is None:\n",
    "        k = min(m, n)\n",
    "    else:\n",
    "        k = min(k, m, n)\n",
    "\n",
    "    # Streaming compute task: only builds left modes and singular values\n",
    "    def compute_task():\n",
    "        # Initial batch\n",
    "        B0 = A[:, :batch_size]\n",
    "        Q, R = qr(B0, mode='economic')\n",
    "        U, S, _ = svd(R, full_matrices=False)\n",
    "        modes = Q @ U[:, :k]\n",
    "        sing  = S[:k]\n",
    "        # Iterate over remaining batches\n",
    "        for start in range(batch_size, n, batch_size):\n",
    "            B = A[:, start:start+batch_size]\n",
    "            weighted = ff * (modes @ np.diag(sing))\n",
    "            concat   = np.concatenate((weighted, B), axis=1)\n",
    "            Q, R    = qr(concat, mode='economic')\n",
    "            U, S, _ = svd(R, full_matrices=False)\n",
    "            idx      = np.argsort(S)[::-1][:k]\n",
    "            sing     = S[idx]\n",
    "            modes    = Q @ U[:, idx]\n",
    "        return modes, sing\n",
    "\n",
    "    # Profile and capture modes, singular values in one pass\n",
    "    t0 = time.time()\n",
    "    peak_mem, (modes, sing) = memory_usage(\n",
    "        (compute_task, (), {}),\n",
    "        retval=True,\n",
    "        max_usage=True,\n",
    "        **mem_kwargs\n",
    "    )\n",
    "    elapsed = time.time() - t0\n",
    "\n",
    "    # Reconstruct via projection: A_rec = modes @ (modes^T @ A)\n",
    "    proj = modes.T @ A                  # shape (k, n)\n",
    "    A_rec = modes @ proj                # shape (m, n)\n",
    "    recon_err = np.linalg.norm(A - A_rec, ord='fro')\n",
    "\n",
    "    # Energy captured\n",
    "    total_energy = np.sum((sing)**2)\n",
    "    energy = float(np.linalg.norm(A_rec, ord='fro')**2 / np.linalg.norm(A, ord='fro')**2)\n",
    "\n",
    "\n",
    "    # Condition numbers\n",
    "    cond_full    = float(sing[0] / sing[-1])\n",
    "    cond_trunc   = cond_full\n",
    "\n",
    "    # Package results\n",
    "    results = {\n",
    "        'method': 'Streaming SVD',\n",
    "        'dataset': os.path.basename(nc_path),\n",
    "        'shape':    (m, n),\n",
    "        'k':        k,\n",
    "        'elapsed_time_s': float(elapsed),\n",
    "        'peak_memory_MiB': float(peak_mem),\n",
    "        'reconstruction_error': float(recon_err),\n",
    "        'energy_captured':      float(energy),\n",
    "        'cond_full':            cond_full,\n",
    "        'cond_trunc':           cond_trunc\n",
    "    }\n",
    "\n",
    "    # Print unified report\n",
    "    print(f\"=== {results['method']} on {results['dataset']} (m={m}, n={n}, k={k}) ===\")\n",
    "    for key, val in results.items():\n",
    "        if key not in ('method', 'dataset', 'shape'):\n",
    "            print(f\"{key.replace('_',' ').capitalize():<20}: {val}\")\n",
    "\n",
    "    # Append to JSONL\n",
    "    if output_file:\n",
    "        os.makedirs(os.path.dirname(output_file) or '.', exist_ok=True)\n",
    "        safe = {kk: (vv.item() if hasattr(vv, 'item') else vv) for kk, vv in results.items()}\n",
    "        with open(output_file, 'a') as f:\n",
    "            f.write(json.dumps(safe) + '\\n')\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3d10438",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Streaming SVD on slp.nc (m=16261, n=16071, k=10) ===\n",
      "K                   : 10\n",
      "Elapsed time s      : 8.098215103149414\n",
      "Peak memory mib     : 1240.21875\n",
      "Reconstruction error: 2081826.875\n",
      "Energy captured     : 1.0020482540130615\n",
      "Cond full           : 2385.95849609375\n",
      "Cond trunc          : 2385.95849609375\n"
     ]
    }
   ],
   "source": [
    "res_stream = run_streaming_svd('slp.nc', var_name='msl', k=10, ff=0.95, batch_size=200, output_file='svd_results/streaming_svd_k10_ff95.jsonl', multiprocess=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
