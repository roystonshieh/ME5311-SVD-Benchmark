{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc79ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5850d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy.linalg import norm\n",
    "from sklearn.utils.extmath import randomized_svd  # For randomized SVD\n",
    "from memory_profiler import memory_usage\n",
    "\n",
    "# --- File paths ---\n",
    "base_path = r'G:\\My Drive\\NUS\\NUS Y6S1\\ME5311\\PROJECT_2420_ME5311'\n",
    "slp_path = os.path.join(base_path, 'slp.nc')\n",
    "t2m_path = os.path.join(base_path, 't2m.nc')\n",
    "\n",
    "# --- Load datasets ---\n",
    "ds_slp = xr.open_dataset(slp_path)\n",
    "ds_t2m = xr.open_dataset(t2m_path)\n",
    "\n",
    "slp = ds_slp['msl'].values\n",
    "t2m = ds_t2m['t2m'].values\n",
    "timestamps = ds_slp['time'].values\n",
    "lats = ds_slp['latitude'].values\n",
    "longs = ds_slp['longitude'].values\n",
    "\n",
    "# --- Reshape and center SLP ---\n",
    "n_time, n_lat, n_lon = slp.shape\n",
    "A_slp = slp.reshape(n_time, -1).T\n",
    "A_mean_slp = A_slp.mean(axis=1, keepdims=True)\n",
    "A_centered_slp = A_slp - A_mean_slp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa2ffa46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Define number of singular values/vectors to compute ---\n",
    "k = 500  # Number of singular values to compute, adjust based on your needs\n",
    "n_oversamples = 10  # Extra samples for improved accuracy\n",
    "n_iter = 5  # Number of power iterations for enhancing accuracy\n",
    "\n",
    "# --- Define Randomized SVD function with monitoring ---\n",
    "def perform_randomized_svd_with_monitoring(A, k, n_oversamples=10, n_iter=5):\n",
    "    \"\"\"Performs Randomized SVD with runtime and memory tracking\"\"\"\n",
    "    print(f\"Performing Randomized SVD on SLP data (k={k}, oversamples={n_oversamples}, iter={n_iter})...\")\n",
    "    \n",
    "    def randomized_svd_task():\n",
    "        global U_slp, S_slp, VT_slp\n",
    "        \n",
    "        # Use sklearn's randomized_svd\n",
    "        U_slp, S_slp, VT_slp = randomized_svd(\n",
    "            A, \n",
    "            n_components=k,\n",
    "            n_oversamples=n_oversamples,\n",
    "            n_iter=n_iter,\n",
    "            random_state=42  # For reproducibility\n",
    "        )\n",
    "\n",
    "    # Monitor runtime and memory usage\n",
    "    start = time.time()\n",
    "    mem_usage = memory_usage(randomized_svd_task, max_usage=True)\n",
    "    elapsed = time.time() - start\n",
    "    \n",
    "    return elapsed, mem_usage\n",
    "\n",
    "# --- Run Randomized SVD with performance monitoring ---\n",
    "elapsed_slp, peak_mem_slp = perform_randomized_svd_with_monitoring(\n",
    "    A_centered_slp, k, n_oversamples, n_iter\n",
    ")\n",
    "\n",
    "# --- SVD result shapes (informational) ---\n",
    "print(f\"A shape: {A_slp.shape}\")\n",
    "print(f\"U shape: {U_slp.shape}, S shape: {S_slp.shape}, VT shape: {VT_slp.shape}\")\n",
    "print(f\"Randomized SVD with k={k}, oversamples={n_oversamples}, iterations={n_iter}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12586e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Accuracy (Reconstruction Error) ---\n",
    "def calculate_reconstruction_error(U, S, VT, A_original, A_mean):\n",
    "    \"\"\"Calculate reconstruction error using Frobenius norm\"\"\"\n",
    "    # Create diagonal S matrix for matrix multiplication\n",
    "    S_diag = np.diag(S)\n",
    "    \n",
    "    # Reconstruct the original matrix\n",
    "    A_reconstructed = U @ S_diag @ VT + A_mean\n",
    "    \n",
    "    # Calculate relative error\n",
    "    error = norm(A_original - A_reconstructed) / norm(A_original)\n",
    "    return error, A_reconstructed\n",
    "\n",
    "# --- Noise Robustness Test ---\n",
    "def test_noise_robustness(A_centered, A_original, A_mean, k, n_oversamples=10, n_iter=5, noise_scale=0.01):\n",
    "    \"\"\"Test Randomized SVD robustness against Gaussian noise\"\"\"\n",
    "    np.random.seed(0)  # For reproducibility\n",
    "    noise = np.random.normal(scale=noise_scale, size=A_centered.shape)\n",
    "    A_noisy = A_centered + noise\n",
    "    \n",
    "    # Perform Randomized SVD on noisy data\n",
    "    U_noisy, S_noisy, VT_noisy = randomized_svd(\n",
    "        A_noisy, \n",
    "        n_components=k,\n",
    "        n_oversamples=n_oversamples,\n",
    "        n_iter=n_iter,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    # Calculate reconstruction error with noise\n",
    "    S_noisy_diag = np.diag(S_noisy)\n",
    "    A_reconstructed_noisy = U_noisy @ S_noisy_diag @ VT_noisy + A_mean\n",
    "    \n",
    "    error = norm(A_original - A_reconstructed_noisy) / norm(A_original)\n",
    "    return error\n",
    "\n",
    "# Calculate reconstruction error\n",
    "reconstruction_error, A_reconstructed = calculate_reconstruction_error(\n",
    "    U_slp, S_slp, VT_slp, A_slp, A_mean_slp\n",
    ")\n",
    "\n",
    "# Test noise robustness\n",
    "noise_error = test_noise_robustness(\n",
    "    A_centered_slp, A_slp, A_mean_slp, k, n_oversamples, n_iter\n",
    ")\n",
    "\n",
    "# --- Report results ---\n",
    "print(\"\\n===== Randomized SVD Results for SLP =====\")\n",
    "print(f\"Number of singular values/vectors: k = {k}\")\n",
    "print(f\"Number of oversamples: {n_oversamples}\")\n",
    "print(f\"Number of power iterations: {n_iter}\")\n",
    "print(f\"Runtime: {elapsed_slp:.2f} seconds\")\n",
    "print(f\"Peak memory usage: {peak_mem_slp:.2f} MiB\")\n",
    "print(f\"Reconstruction error (Frobenius norm): {reconstruction_error:.6e}\")\n",
    "print(f\"Noise robustness (error with Gaussian noise): {noise_error:.6e}\")\n",
    "\n",
    "# --- Cumulative energy (estimated) ---\n",
    "total_energy = np.sum(S_slp**2)\n",
    "cumulative_energy = np.cumsum(S_slp**2) / total_energy\n",
    "\n",
    "# Note: Since randomized SVD only computes k values, we can only show the\n",
    "# energy captured by these k components, not determine how many are needed for 90/95%\n",
    "print(f\"Energy captured by {k} components: {cumulative_energy[-1]:.6f} ({cumulative_energy[-1]*100:.2f}%)\")\n",
    "\n",
    "# --- Optional: Save results to file for later comparison ---\n",
    "results = {\n",
    "    \"method\": \"Randomized SVD\",\n",
    "    \"k_value\": k,\n",
    "    \"n_oversamples\": n_oversamples,\n",
    "    \"n_iterations\": n_iter,\n",
    "    \"runtime\": elapsed_slp,\n",
    "    \"memory_usage\": peak_mem_slp,\n",
    "    \"reconstruction_error\": float(reconstruction_error),\n",
    "    \"noise_robustness\": float(noise_error),\n",
    "    \"energy_captured\": float(cumulative_energy[-1]),\n",
    "    \"top_singular_values\": S_slp[:10].tolist()  # Save first 10 singular values\n",
    "}\n",
    "\n",
    "# Save as JSON (optional)\n",
    "import json\n",
    "with open(\"randomized_svd_results.json\", \"w\") as f:\n",
    "    json.dump(results, f, indent=4)\n",
    "\n",
    "# --- Plot singular value decay ---\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.semilogy(range(1, len(S_slp) + 1), S_slp, 'o-')\n",
    "plt.title(f'Singular Value Decay (k={k}) - Randomized SVD')\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('Singular Value (log scale)')\n",
    "plt.grid(True)\n",
    "plt.savefig('randomized_svd_singular_values.png', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "# --- Plot cumulative energy ---\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, len(S_slp) + 1), cumulative_energy, 'o-')\n",
    "plt.title('Cumulative Energy vs. Number of Modes - Randomized SVD')\n",
    "plt.xlabel('Number of Modes')\n",
    "plt.ylabel('Cumulative Energy Fraction')\n",
    "plt.grid(True)\n",
    "plt.savefig('randomized_svd_cumulative_energy.png', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "# --- Optional: Compare first few spatial modes with full SVD if available ---\n",
    "# If you've run full SVD previously and saved U_full, you can compare:\n",
    "# from numpy.linalg import svd\n",
    "# _, _, VT_full = svd(A_centered_slp, full_matrices=False)\n",
    "# \n",
    "# plt.figure(figsize=(12, 8))\n",
    "# for i in range(min(4, k)):\n",
    "#     plt.subplot(2, 2, i+1)\n",
    "#     corr = np.abs(np.corrcoef(VT_slp[i], VT_full[i])[0, 1])\n",
    "#     plt.plot(VT_full[i], label='Full SVD')\n",
    "#     plt.plot(VT_slp[i], '--', label='Randomized SVD')\n",
    "#     plt.title(f'Mode {i+1}, Correlation: {corr:.4f}')\n",
    "#     plt.legend()\n",
    "# plt.tight_layout()\n",
    "# plt.savefig('randomized_vs_full_svd_modes.png', dpi=300)\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
