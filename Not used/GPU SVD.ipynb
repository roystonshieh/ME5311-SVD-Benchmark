{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d60eaa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement torch-directml (from versions: none)\n",
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "ERROR: No matching distribution found for torch-directml\n"
     ]
    }
   ],
   "source": [
    "pip install torch-directml\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ddc18811",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using backend: CPU, device: cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Try CUDA\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    backend = \"CUDA\"\n",
    "# Try DirectML on AMD/Windows\n",
    "else:\n",
    "    try:\n",
    "        import torch_directml\n",
    "        device = torch_directml.device()\n",
    "        backend = \"DirectML\"\n",
    "    except ImportError:\n",
    "        device = torch.device(\"cpu\")\n",
    "        backend = \"CPU\"\n",
    "\n",
    "print(f\"Using backend: {backend}, device: {device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ba17fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy.linalg import norm\n",
    "import torch\n",
    "from memory_profiler import memory_usage\n",
    "\n",
    "# --- Check if GPU is available ---\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    gpu_name = torch.cuda.get_device_name(0)\n",
    "    print(f\"GPU available: {gpu_name}\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"No GPU available, falling back to CPU\")\n",
    "\n",
    "# --- File paths ---\n",
    "base_path = r'G:\\My Drive\\NUS\\NUS Y6S1\\ME5311\\PROJECT_2420_ME5311'\n",
    "slp_path = os.path.join(base_path, 'slp.nc')\n",
    "t2m_path = os.path.join(base_path, 't2m.nc')\n",
    "\n",
    "# --- Load datasets ---\n",
    "ds_slp = xr.open_dataset(slp_path)\n",
    "ds_t2m = xr.open_dataset(t2m_path)\n",
    "\n",
    "slp = ds_slp['msl'].values\n",
    "t2m = ds_t2m['t2m'].values\n",
    "timestamps = ds_slp['time'].values\n",
    "lats = ds_slp['latitude'].values\n",
    "longs = ds_slp['longitude'].values\n",
    "\n",
    "# --- Reshape and center SLP ---\n",
    "n_time, n_lat, n_lon = slp.shape\n",
    "A_slp = slp.reshape(n_time, -1).T  # shape: (n_space, n_time)\n",
    "A_mean_slp = A_slp.mean(axis=1, keepdims=True)\n",
    "A_centered_slp = A_slp - A_mean_slp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad42ddca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Define parameters ---\n",
    "k = None  # Full SVD (will be truncated after computation if needed)\n",
    "\n",
    "# --- Define GPU-accelerated SVD function with monitoring ---\n",
    "def perform_gpu_svd_with_monitoring(A):\n",
    "    \"\"\"Performs GPU-accelerated SVD with runtime and memory tracking\"\"\"\n",
    "    print(f\"Performing GPU-accelerated SVD on SLP data using {device}...\")\n",
    "    \n",
    "    def gpu_svd_task():\n",
    "        global U_slp, S_slp, VT_slp\n",
    "        \n",
    "        # Convert numpy array to PyTorch tensor and move to GPU\n",
    "        A_tensor = torch.tensor(A, dtype=torch.float32).to(device)\n",
    "        \n",
    "        # Perform SVD on GPU\n",
    "        U_tensor, S_tensor, V_tensor = torch.linalg.svd(A_tensor, full_matrices=False)\n",
    "        \n",
    "        # Move results back to CPU and convert to numpy\n",
    "        U_slp = U_tensor.cpu().numpy()\n",
    "        S_slp = S_tensor.cpu().numpy()\n",
    "        VT_slp = V_tensor.transpose(0, 1).cpu().numpy()\n",
    "        \n",
    "        # Clear GPU cache to free memory\n",
    "        torch.cuda.empty_cache() if torch.cuda.is_available() else None\n",
    "\n",
    "    # Monitor runtime and memory usage\n",
    "    start = time.time()\n",
    "    mem_usage = memory_usage(gpu_svd_task, max_usage=True)\n",
    "    elapsed = time.time() - start\n",
    "    \n",
    "    return elapsed, mem_usage\n",
    "\n",
    "# --- Run GPU-accelerated SVD with performance monitoring ---\n",
    "elapsed_slp, peak_mem_slp = perform_gpu_svd_with_monitoring(A_centered_slp)\n",
    "\n",
    "# --- SVD result shapes (informational) ---\n",
    "print(f\"A shape: {A_slp.shape}\")\n",
    "print(f\"U shape: {U_slp.shape}, S shape: {S_slp.shape}, VT shape: {VT_slp.shape}\")\n",
    "print(f\"GPU-accelerated SVD completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40385441",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Truncate to top k components if desired ---\n",
    "k_truncate = 500  # Number of components to keep for analysis\n",
    "U_trunc = U_slp[:, :k_truncate]\n",
    "S_trunc = S_slp[:k_truncate]\n",
    "VT_trunc = VT_slp[:k_truncate, :]\n",
    "\n",
    "# --- Accuracy (Reconstruction Error) ---\n",
    "def calculate_reconstruction_error(U, S, VT, A_original, A_mean):\n",
    "    \"\"\"Calculate reconstruction error using Frobenius norm\"\"\"\n",
    "    # Create diagonal S matrix for matrix multiplication\n",
    "    S_diag = np.diag(S)\n",
    "    \n",
    "    # Reconstruct the original matrix\n",
    "    A_reconstructed = U @ S_diag @ VT + A_mean\n",
    "    \n",
    "    # Calculate relative error\n",
    "    error = norm(A_original - A_reconstructed) / norm(A_original)\n",
    "    return error, A_reconstructed\n",
    "\n",
    "# --- Noise Robustness Test ---\n",
    "def test_noise_robustness(A_centered, A_original, A_mean, noise_scale=0.01):\n",
    "    \"\"\"Test GPU SVD robustness against Gaussian noise\"\"\"\n",
    "    np.random.seed(0)  # For reproducibility\n",
    "    noise = np.random.normal(scale=noise_scale, size=A_centered.shape)\n",
    "    A_noisy = A_centered + noise\n",
    "    \n",
    "    # Convert to PyTorch tensor and move to GPU\n",
    "    A_noisy_tensor = torch.tensor(A_noisy, dtype=torch.float32).to(device)\n",
    "    \n",
    "    # Perform SVD on noisy data\n",
    "    U_noisy_tensor, S_noisy_tensor, V_noisy_tensor = torch.linalg.svd(A_noisy_tensor, full_matrices=False)\n",
    "    \n",
    "    # Move results back to CPU and convert to numpy\n",
    "    U_noisy = U_noisy_tensor.cpu().numpy()\n",
    "    S_noisy = S_noisy_tensor.cpu().numpy()\n",
    "    VT_noisy = V_noisy_tensor.transpose(0, 1).cpu().numpy()\n",
    "    \n",
    "    # Truncate if needed\n",
    "    U_noisy = U_noisy[:, :k_truncate]\n",
    "    S_noisy = S_noisy[:k_truncate]\n",
    "    VT_noisy = VT_noisy[:k_truncate, :]\n",
    "    \n",
    "    # Calculate reconstruction error with noise\n",
    "    S_noisy_diag = np.diag(S_noisy)\n",
    "    A_reconstructed_noisy = U_noisy @ S_noisy_diag @ VT_noisy + A_mean\n",
    "    \n",
    "    error = norm(A_original - A_reconstructed_noisy) / norm(A_original)\n",
    "    \n",
    "    # Clear GPU cache\n",
    "    torch.cuda.empty_cache() if torch.cuda.is_available() else None\n",
    "    \n",
    "    return error\n",
    "\n",
    "# Calculate reconstruction error (using truncated components)\n",
    "reconstruction_error, A_reconstructed = calculate_reconstruction_error(\n",
    "    U_trunc, S_trunc, VT_trunc, A_slp, A_mean_slp\n",
    ")\n",
    "\n",
    "# Test noise robustness\n",
    "noise_error = test_noise_robustness(\n",
    "    A_centered_slp, A_slp, A_mean_slp\n",
    ")\n",
    "\n",
    "# --- Report results ---\n",
    "print(\"\\n===== GPU-accelerated SVD Results for SLP =====\")\n",
    "print(f\"Device used: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "print(f\"Runtime: {elapsed_slp:.2f} seconds\")\n",
    "print(f\"Peak memory usage: {peak_mem_slp:.2f} MiB\")\n",
    "print(f\"Reconstruction error with {k_truncate} modes (Frobenius norm): {reconstruction_error:.6e}\")\n",
    "print(f\"Noise robustness (error with Gaussian noise): {noise_error:.6e}\")\n",
    "\n",
    "# --- Cumulative energy ---\n",
    "total_energy = np.sum(S_slp**2)\n",
    "cumulative_energy = np.cumsum(S_slp**2) / total_energy\n",
    "energy_90 = np.where(cumulative_energy >= 0.9)[0][0] + 1\n",
    "energy_95 = np.where(cumulative_energy >= 0.95)[0][0] + 1\n",
    "\n",
    "print(f\"Number of modes for 90% energy: {energy_90}\")\n",
    "print(f\"Number of modes for 95% energy: {energy_95}\")\n",
    "\n",
    "# --- Optional: Save results to file for later comparison ---\n",
    "results = {\n",
    "    \"method\": \"GPU-accelerated SVD\",\n",
    "    \"device\": str(device),\n",
    "    \"gpu_name\": torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"None\",\n",
    "    \"runtime\": elapsed_slp,\n",
    "    \"memory_usage\": peak_mem_slp,\n",
    "    \"reconstruction_error\": float(reconstruction_error),\n",
    "    \"noise_robustness\": float(noise_error),\n",
    "    \"modes_90pct_energy\": int(energy_90),\n",
    "    \"modes_95pct_energy\": int(energy_95),\n",
    "    \"top_singular_values\": S_slp[:10].tolist()  # Save first 10 singular values\n",
    "}\n",
    "\n",
    "# Save as JSON (optional)\n",
    "import json\n",
    "with open(\"gpu_svd_results.json\", \"w\") as f:\n",
    "    json.dump(results, f, indent=4)\n",
    "\n",
    "# --- Plot singular value decay ---\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.semilogy(range(1, 101), S_slp[:100], 'o-')\n",
    "plt.title('Singular Value Decay (Top 100) - GPU-accelerated SVD')\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('Singular Value (log scale)')\n",
    "plt.grid(True)\n",
    "plt.savefig('gpu_svd_singular_values.png', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "# --- Plot cumulative energy ---\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, min(1001, len(cumulative_energy))), cumulative_energy[:1000])\n",
    "plt.axhline(y=0.9, color='r', linestyle='--', label='90% Energy')\n",
    "plt.axhline(y=0.95, color='g', linestyle='--', label='95% Energy')\n",
    "plt.title('Cumulative Energy vs. Number of Modes - GPU-accelerated SVD')\n",
    "plt.xlabel('Number of Modes')\n",
    "plt.ylabel('Cumulative Energy Fraction')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig('gpu_svd_cumulative_energy.png', dpi=300)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
